{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Building a Hybrid Product Recommendation System for Amazon using Customer Ratings and Reviews](https://github.com/dametreusv/amazon_hybrid_recommendation_system)\n",
    "----\n",
    "#### Source code, in depth analysis, and full modeling and predictions can be accessed via links throughout this report.\n",
    "[Data Wrangling](https://github.com/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_wrangle.ipynb) - [Exploratory Data Analysis](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_analysis.ipynb) - [Milestone Report](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_milestone_report.ipynb) - [Simple Keyword Search](https://github.com/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_keyword_simple.ipynb) - [Collaborative Filtering Recommender](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/rating_distributions.png'>\n",
    "\n",
    "----\n",
    "## Executive Summary\n",
    "\n",
    "[Amazon](https://www.amazon.com) is a multinational technology company based in Seattle, Washington, that focuses on e-commerce, cloud computing, digital streaming, artificial intelligence and more.  One of its most popular services is the [e-commerce](https://s3.amazonaws.com/amazon-reviews-pds/readme.html) website ‘Amazon.com.’  One of the ways Amazon keeps its shoppers engaged is by way of its product recommendation system. The product recommendation system uses content and collaborative based filtering, looking at a shopper’s past purchases and purchases by shoppers who purchased similar items and then recommends items that the shopper may like based off of these two behaviors. Collaborative filtering enables the shopper to see items from other categories, while content based filtering allows shoppers to see domain specific items.\n",
    "\n",
    "Unlike content based filtering, which suggest only similar products or domain specific products, collaborative filtering recommendation systems allows users to find similar products and jump (or switch) to other categories of products based on similarities with other users and products.  In this case, we explore 3 different ways to use collaborative based filtering.\n",
    "\n",
    "1. The first method suggests products that other users like to a specific user based on their rating of a specific product.  Essentially, it finds users that rated a product similar to the specific user and returns the top products the other users liked.\n",
    "\n",
    "\n",
    "2. The second method predicts what products a user may like based on past rating history and the rating history of other users.  This method is not specific to the rating of one product like the first method.\n",
    "\n",
    "\n",
    "3. The third method predicts products similar to a specific product by finding the nearest neighbors to that product.  This method is good for users who may want to purchase products as bundles.\n",
    "\n",
    "\n",
    "We evaluate our methods by:\n",
    "- Testing the recommendation systems to see what products they return.\n",
    "- Understanding matrix factorization and how it effects collaborative filtering systems.\n",
    "- Selecting and tuning various recommendation algorithms to find the best performing algorithm.\n",
    "- Understanding estimated ratings vs. true ratings.\n",
    "- Performing precision@k and recall@k tests.\n",
    "\n",
    "The [dataset](https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt) that is used has 5,813,109 total reviews/ratings from 3,649,861 unique customers that review 11,502 unique products that are in the categories of automotive, digital music, toys, music, cameras, video dvd, tools, digital ebook, baby, musical instruments, books, watches, digital video download, video, mobile apps, outdoors, home imporvement, PC, video games, lawn & garden, sports, electronics, wireless, home entertainment, kitchen, office products, home, health & personal care and shoes.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/recommendations.png' width='550'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Introduction\n",
    "\n",
    "Amazon's website offers a plethora of different types of products ranging from automotive to sports to groceries to hardware tools to digital products and more. A shopper can purchase almost anything on Amazon.com while taking advantage of its recommendation system.\n",
    "\n",
    "[According to Neil DeGrasse Tyson](https://www.youtube.com/watch?v=0NEmgA2FlO8&list=WL&index=40&t=308s), “If you track what I buy at a store, and then send me coupons based on what you think I’m going to buy next based on what I bought before. You have denied me the chance of stumbling upon something that I never thought of buying and that takes away my freedoms and I don’t like that. It’s the art of browsing. If I have to look up this word in the dictionary and get through 6 other words. You learn other words in route to the word that you’re targeting.” Based on these comments, which are similar to how many people feel when they shop or look at content on the internet, we want to build a hybrid recommendation engine that will not only recommend similar products but also recommend products in other categories, genres or fields to a shopper in order to help them find what they might not have been looking for.\n",
    "\n",
    "\n",
    "### Problem Statement:\n",
    "“If you know my previous habits, you’re assuming I’m going to stay that way for the rest of my life. You’re trying to channel me into buying a product. I want to experience this world by stepping where I’ve never stepped before and buying something I never thought of buying.”\n",
    "- Neil Degrasse Tyson\n",
    "\n",
    "Recommendation systems are great at recommending similar products to shoppers, but they tend to be too concentrated, which does not let a shopper go outside their comfort zone or see something they may not have known they wanted. For example, watching a video on Youtube will start to flood a user’s browser with several similar videos and not enough diversity in content. As for the case with Amazon, we want to build a recommendation system that recommends a diverse selection of items or content to users as needed.\n",
    "\n",
    "### Approach:\n",
    "We will be making a multi-use recommendation system that will take in collaborative based filtering in order to recommend a diverse selection of products or content that a user may like. Some recommendations will be very similar to the user’s past purchases while others will be from other categories, genres or domains. This is to help give the user a look at various items they may not have known they wanted.  Visual and statistical EDA are performed to understand the correlation between customers and products, and ratings and recommendations.  The Surprise Scikit module is used to help in making product recommendations based on similar users and similar products.\n",
    "\n",
    "### The Client:\n",
    "People who like to shop online, stream or read content, support their favorite charities or try out certain products before they buy are our targeted clients. Essentially users of Amazon.com or Amazon Prime members. These people like the randomness of what shopping online may entail. The randomness of it enriches their lives. They are looking for certain products but love the idea of finding items or content they weren’t looking for or didn’t know they may have needed. Our clients know what they want but know they won’t be the same person tomorrow as they are today.\n",
    "\n",
    "### Dataset\n",
    "The [Amazon Customer Reviews Dataset](https://s3.amazonaws.com/amazon-reviews-pds/readme.html) is a robust set of tsv files that house over a hundred million reviews that express opinions and experiences of shoppers regarding products on the Amazon.com website. This makes Amazon Customer Reviews a rich source of information for Natural Language Processing (NLP), Information Retrieval (IR) and Machine Learning (ML). Reviews range from 1995 to 2015 and are compiled from customers in 5 countries.\n",
    "\n",
    "Most of the tsv files only contain reviews for products in one category (toys, software, shoes, lawn and garden, etc.), but there are millions of reviews in each tsv file. We are going to be using a [multilingual reviews dataset (US)](https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt) which contains multiple categories and several million reviews.\n",
    "\n",
    "The dataset contains 6.9 million+ reviews on a 5-star rating scale from 4 million+ different customers. There are 86,000+ products in 16,000+ product parents ranging in 39 different categories from August 8th, 1995 to August 31, 2015. Some of the categories are mobile apps, digital ebooks, home entertainment, video games, home improvement, automotive, software, beauty and much much more.\n",
    "\n",
    "### Overview\n",
    "\n",
    "In our analysis we were able to:\n",
    "\n",
    "- Look at the distribution of ratings among products and customers.\n",
    "- Determine the most popular products and categories.\n",
    "- Look at the highest rated categories and see what affects rating averages.\n",
    "- Observe how ratings change over time.\n",
    "- Determine the point where the Amazon marketplace exploded in growth.\n",
    "\n",
    "We have found that:\n",
    "\n",
    "- Over 60% of all reviews receive 5 star ratings.\n",
    "- Most products have between 100 and 1,000 reviews.\n",
    "- Most customers give between 1 and 10 reviews.\n",
    "- Out of 11,500+ products, less than 250 have an average rating under 3.0.\n",
    "- 90% of the Amazon marketplace revolves around books, music, movies and mobile apps.\n",
    "- The top 3 categories have intangible products (digital).\n",
    "- The range in the difference of average categorical ratings is 0.84, from 3.84 to 4.68.\n",
    "- Over time the average annual ratings stay between 4.1 and 4.4.\n",
    "- The marketplace has grown exponentially since 2011.\n",
    "- Average product ratings are mostly affected by 5, 4 and 1 star reviews.\n",
    "- Most reviews occur in January and December, likely because of the holidays.\n",
    "\n",
    "We use 3 different methods for recommending products.  The first method suggests products that other users like to a specific user based on their rating of a specific product.  The second method predicts what products a user may like based on past rating history and the rating history of other users.  The third method predicts products similar to a specific product by finding the nearest neighbors to that product.  \n",
    "\n",
    "We evaluate our methods by:\n",
    "- Testing the recommendation systems to see what products they return.\n",
    "- Understanding estimated ratings vs. true ratings.\n",
    "- Performing precision@k and recall@k tests.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## [Data Wrangling](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_milestone_report.ipynb#wrangle)\n",
    "After looking through the initial data, we decided to use the Amazon [multilingual reviews dataset (US)](https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt) which contains almost 7 million reviews on various Amazon products.  The dataset contains 6.9 million+ reviews on a 5-star rating scale from 4 million+ different customers. There are 86,000+ products in 16,000+ product parents ranging in 39 different categories from August 8th, 1995 to August 31, 2015. Some of the categories are mobile apps, digital ebooks, home entertainment, video games, home improvement, automotive, software, beauty and much much more.  The dataset houses information about unique customers, reviews, unique products, categories, star ratings, helpful votes, review content and review date.\n",
    "\n",
    "Through data wrangling, we were able to:\n",
    "- Read in raw data\n",
    "- Standardize columns & product categories\n",
    "- Drop products with under 100 reviews (helped in dropping products that were completely the same but had different spelling or punctuations)\n",
    "- Discover the differences between product parent, product title and product ID (including product category)\n",
    "- Drop rows with missing or duplicated data\n",
    "- Handle date-time objects\n",
    "- Create columns including purchased counts, year, month and month-year\n",
    "\n",
    "We are left with 5.8+ million reviews by 3.6+ million unique customers on 11,500+ unique products from 29 product categories.\n",
    "\n",
    "*Note: The drop off from 86,000+ unique products to 11,500+ unique products appears large but most of the drop offs were from products that were exactly the same but had different punctuations or typos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## [Exploratory Data Analysis](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_milestone_report.ipynb#eda)\n",
    "\n",
    "#### [Distribution of Ratings Among Products and Customers](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_analysis.ipynb#distribution)\n",
    "\n",
    "According to the graphs below, we have discovered that:\n",
    "\n",
    "**Cumulative Distribution of Ratings**\n",
    "- Over 60% of ratings receive 5 stars, while 1 star ratings occur less than 10% of the time. Ratings between 2 and 4 stars occur roughly 30% of the time. This means positive ratings occur over 80% of the time, while negative ratings occur roughly 15% of the time and neutral ratings occur 5% of the time.\n",
    "\n",
    "**Cumulative Distribution of Ratings per Product, 100 min**\n",
    "- The cumulative distribution of products begins with 100. 60% of all products have between 100 and 500 reviews, while roughly 90% of products have up to 1,000 reviews. Rouhgly 10% of products have between 1,000 and 10,000 reviews and some have over 10,000 reviews.\n",
    "\n",
    "**Distribution of Ratings per User**\n",
    "- Roughly 75% of all customers have only reviewed products one time, while roughly 24% have reviewed up to 10 products. There is a small percentage that have reviewed between 10 and 100 products and an even smaller percantage that have reviewed over 100 products.\n",
    "\n",
    "- Over 3.5 million customers have given between 1 and 10 reviews on products, while roughly 30,000 have given between 10 and 100 reviews on products. Roughly 300 customers have reviewed between 100 and 500 reviews. and less than 1 customer has reviewed almost 700 products.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/cumulative_distribution.png\"> \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/customer_rating_frequency_long.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Most Popular Products and Categories](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_analysis.ipynb#popular)\n",
    "\n",
    "Candy Crush is the most popular product reviewed on Amazon which is a mobile app. Other items in the top 10 include the Google Chromecast which is a streaming device and Gone Girl which is a novel. Every product in the top 10 has over 25,000 reviews with Candy Crush and The Secret Mystery having over 40,000 reviews.\n",
    "\n",
    "Mobile apps is the most popular category reviewed on Amazon, followed by books, movies and music. 6 of the top 10 categories dominate the marketplace with well over 90% of total ratings and reviews. The top 3 categories are all intangibles, not having any physical attributes.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/top_10.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Ratings Among Product Categories](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_analysis.ipynb#categories)\n",
    "\n",
    "On average, the automotive category has the highest rated products (4.68), followed by digital music purchase (4.60) and toys (4.44). The lowest rated category is shoes (3.84), followed by health & personal care (3.84) and home (3.89). The range in average ratings from highest to lowest is 0.84.\n",
    "\n",
    "The categories rated low seem to be categories where customers don't know what they may be receiving, variability of quality among the same type of products, while the categories rated highly seem to have less variability in what one can receive.\n",
    "\n",
    "As stated earlier, music, books, movies and mobile apps dominate the Amazon marketplace. The biggest factor that seems to determine a product category's average rating is how many 5 stars, 4 stars and 1 stars that category receives. 2 stars and 3 stars appears to remain close to the same proportion throughout each category.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/category_ratings.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Ratings by Year](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_analysis.ipynb#year)\n",
    "\n",
    "Previously, we have discovered that products mostly recieve 5 star ratings so it is not a surprise that the median is 5 stars. We can see that when amazon first introduced product reviews, there has been a drop and balance of average reviews on an annual basis. Initially the average product reviews were just under 4.8 and dropped to roughly 4.1 in 2004. Over time, the average annual product review has stayed between 4.1 and 4.4.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/average_rating_annual.png\">\n",
    "\n",
    "As seen below, the Amazon marketplace started gaining popularity in 2010 and exploded exponentially from 2011 onwards. Not only did the marketplace explode, it exploded with quality products as we can see higher rated reviews are steeper in the growth than lower rated reviews. Although there seems to be a steep drop off from 2014 to 2015, it is worth noting that the last review available on this dataset was on August 31, 2015 so there are missing reviews for one third of the year for 2015.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/annual_ratings.png\">\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/annual_ratings_2.png\" width='800'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Ratings by Month](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_analysis.ipynb#month)\n",
    "\n",
    "Over time, the distribution of monthly reviews matches the most current annual observation of monthly reviews. December has the most reviews, followed by January. This is likely because of the holiday season and the purchasing and exchange of gifts. January is likely high because money is often a popular gift during the holidays and customers make purchases after the holidays are over. April, May and June have the lowest review frequencies, possibly because of the change in weather and customers are likely more inclined to spend money on experiences (vacations and trips) rather than on products.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/monthly_distribution.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Ratings Over Time](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_analysis.ipynb#time)\n",
    "\n",
    "The breakdown of ratings over time changes slightly over time with no clear spike in changes to rating behavior. Although we can see where the spike in reviews occur for each year starting in 2011. As previously observed, these spikes are in January and December of each year.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/over_time.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Sum Up Our Exploratory Data Analysis:\n",
    "\n",
    "- Positive ratings occur over 80% of the time, while negative ratings occur roughly 15% of the time and neutral ratings occur 5% of the time. Roughly 75% of all customers have only reviewed products one time, while roughly 24% have reviewed up to 10 products. 1 customer has reviewed almost 700 products. Well over 50% of products average a 4.5 or higher rating, while over 90% have a 3.5 or higher rating.\n",
    "\n",
    "\n",
    "- Candy Crush is the most popular product reviewed on Amazon which is a mobile app. Every product in the top 10 has over 25,000 reviews with Candy Crush and The Secret Mystery having over 40,000 reviews. 6 of the top 10 categories dominate the marketplace with well over 90% of total ratings and reviews.\n",
    "\n",
    "\n",
    "- The range in average ratings from highest to lowest is 0.84, from 3.84 to 4.68. The categories rated low seem to be categories where customers don't know what they may be receiving, variability of quality among the same type of products, while the categories rated highly seem to have less variability in what one can receive. The biggest factor that seems to determine a product category's average rating is how many 5 stars, 4 stars and 1 stars that category receives.\n",
    "\n",
    "\n",
    "- Over time, the average annual product review has stayed between 4.1 and 4.4. The Amazon marketplace started gaining popularity in 2010 and exploded exponentially from 2011 onwards.\n",
    "\n",
    "\n",
    "- December has the most reviews, followed by January. This is likely because of the holiday season and the purchasing and exchange of gifts. January is likely high because money is often a popular gift during the holidays and customers make purchases after the holidays are over.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## [Recommendation & Filtering Models](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#executive)\n",
    "\n",
    "#### [Simple Keyword Search](https://github.com/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_keyword_simple.ipynb)\n",
    "\n",
    "A simple keyword search recommender module is built to filter products by keywords based on a user's interest. In this case, the module will filter keywords based on category and product title. The user may enter a word or series of words in as the product title and even refine the search by entering a category, or vice versa. The module will filter by the keywords entered, then rank the results by the rating method chosen by the user and return the desired amount of results.\n",
    "\n",
    "An adjusted rating system was introduced to adjust the rating of each product to account for extreme ratings and balance out ratings for products that had several thousand reviews to products that only had a hundred or so. Products with less reviews were more likely to be affected by a series of ratings than products with more reviews, both positively and negatively. We want a balance. We used the formula: \n",
    "\n",
    "$$score_i = \\frac{\\sum_u r_{ui} + k*\\mu}{n_i+k}$$\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/keyword.png\">\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/keyword_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Simple Collaborative Filtering Recommendation System](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#simple)\n",
    "\n",
    "The purpose of this simple collaborative filtering recommendation system is to show the inner workings behind a basic recommendation system. This recommendation system works behind the notion of:\n",
    "\n",
    "“If you know my previous habits, you’re assuming I’m going to stay that way for the rest of my life. You’re trying to channel me into buying a product. I want to experience this world by stepping where I’ve never stepped before and buying something I never thought of buying.”\n",
    "\n",
    "The simple collaborative filtering recommendation system does the [following steps to recommend products](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#steps) to a customer:\n",
    "\n",
    "1. Takes in a dataset, user and product.\n",
    "2. Filters to all other users that have purchased the same product as the original user.\n",
    "3. Filters to all users that gave the same rating as the original user.\n",
    "4. Filters to all products those users purchased.\n",
    "5. Filters to 5 star products those users purchased.\n",
    "6. Takes the top 10 (or most common) products those users gave 5 stars.\n",
    "7. Returns the products.\n",
    "\n",
    "This recommendation will tell a user what other users like them like. Recommendations are user/product specific. Recommended products are not necessarily similar.\n",
    "\n",
    "*This is not a prediction model, this algorithm was created to give the reader an understanding of how a recommendation system works.*\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/simple.png\">\n",
    "\n",
    "[Test 1](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#test1)\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/simple_2.png\">\n",
    "\n",
    "[Test 3](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Understanding Pivoting, Matrix Factorization and Aggregation](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#understanding)\n",
    "\n",
    "Essentially, when it comes to recommendation systems, it is easy to understand what's going on under the hood by looking at the dataset as a pivoted matrix where the rows are unique customers, the columns are unique products and the values are the star ratings. All other noise is dropped. If a customer has bought a product more than once, the dataset would have to be aggregated (usually by finding the mean of the purchases). Through a matrix it is easier to observe the relationship between customers, products and their ratings.  We are trying to predict what a customer would rate other products based on their previous ratings and the ratings of customers that have given similar ratings.\n",
    "\n",
    "[Example](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#example)\n",
    "\n",
    "- Rows 3 and 4 (Customer IDs 14535682 and 27626904) both gave column 2 (Product ID B0063IH60K) a star rating of 5.0.\n",
    "- Row 3 (Customer ID 14535682) also gave columns 4 and 5 (Product IDs B0094BB4TW and B00992CF6W) a star rating of 5.0.  \n",
    "- Based on this logic, we can assume row 4 (Customer ID 27626904) would give those same columns/products a star rating of 5.0.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/matrix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Surprise](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#surprise)\n",
    "\n",
    "[Surprise](https://surprise.readthedocs.io/en/stable/index.html) is an easy-to-use Python scikit recommender system. It takes in a reader object as a rating scale parameter and loads data from a dataset in the form of a user ID, product ID and values used as a rating system. Through surprise, we may cross validate, train-test-split, predict, find nearest neighbors, tune algorithms, perform grid searches, etc. To get started please click [here](https://surprise.readthedocs.io/en/stable/getting_started.html).  Varous algorithms can be found [here](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html).\n",
    "\n",
    "#### [Sampling the Dataset](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#sampling)\n",
    "\n",
    "The dataset is extremely large and causes the kernels to die as we try to analyze and predict data, so, as we move through the rest of this notebook we will be adjusting our sample sizes accordingly in order to process information in a reasonable amount of time.\n",
    "\n",
    "#### [Selecting and Tuning an Algorithm](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#surprise)\n",
    "\n",
    "We first benchmark our algorithms to see which one gives the best RMSE score.  SVD, equivalent to Probabilistic Matrix Factorization, performs the best and is therefore [selected](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#algorithm) as the base algorithm.  It is then [hypertuned](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#hyperparameter), [tested and retuned](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#testing) against the default SVD settings.  The root mean squared error (RMSE) for the tuned SVD algorithm was 1.0593.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/benchmark.png\" width='400'>\n",
    "\n",
    "#### [Predicting Customer Star Ratings for a Product](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#predicting)\n",
    "\n",
    "After tuning the SVD algorithm, we predict estimated product ratings for specific customers.  While doing so we are able to start [building](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#building) a recommendation system that will recommend the top products for a customer based on estimated ratings of that project.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/est_rui.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Recommending Products to a Customer](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#recommending)\n",
    "\n",
    "After we build the filtering system, we start [testing](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#testing2) how it performs by looking at the various recommendations the system spits out.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/customer_product.png\">\n",
    "\n",
    "[tests 2 & 3](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#test_2)\n",
    "\n",
    "#### [Evaluating Product Recommendations for a Customer](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#evaluating)\n",
    "\n",
    "In order to further measure if our predictions were a success we will evaluate [precision@k and recall@k](https://surprise.readthedocs.io/en/stable/FAQ.html#how-to-compute-precision-k-and-recall-k) where:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/precision_recall.png' width='750'>\n",
    "\n",
    "An item is considered relevant if its true rating 𝑟𝑢𝑖 is greater than a given threshold. An item is considered recommended if its estimated rating 𝑟̂𝑢𝑖 is greater than the threshold, and if it is among the k highest estimated ratings.\n",
    "\n",
    "When viewing the code for evaluating the product recommendations for a customer, we can see that the sampled predictions have fairly high precision scores and recall scores only a few points lower (3 points). The full dataset of predictions have extremely high recall scores with precision scores much lower (11 points). The sampled predictions are closer to consistency in recommending unseen items than the full predictions, but the full predictions are much more consistent in recommending seen items.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/eval.png\" width='600'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Recommending Similar Products](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#similar)\n",
    "\n",
    "In recommending similar products we are using surprise to find the [k nearest neighbors of an item.](https://surprise.readthedocs.io/en/stable/FAQ.html#how-to-get-the-k-nearest-neighbors-of-a-user-or-item)  In this recommendation system, we not only recommend the products similar to a given product, but we display what product category the recommended product belongs to.  Some are obvious, but for recommending products similar to 'Chromecast,' it's best to know what product categories the recommended products belong to. All tests can be found [here](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_recommender_collaborative.ipynb#test__1)\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/product_2.png'>\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/dametreusv/amazon_hybrid_recommendation_system/master/visuals/product.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Limitations\n",
    "\n",
    "We feel that our limited time and computational power prevented us from making the best predictions in selecting and tuning our model as well as making product predictions for specific customers. In the future, we would like to work on training the complete dataset instead of a very small percentage (10% and less).\n",
    "\n",
    "As stated in the [conclusion](https://nbviewer.jupyter.org/github/dametreusv/amazon_hybrid_recommendation_system/blob/master/APR_milestone_report.ipynb#conclusion) of the milestone report, we wanted to also build a content based and hybrid recommendation system as well as work on the cold start problem.  Unfortunately, because of time constraints, we were unable to do that.  Hopefully, in the future, we can add to that in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "\n",
    "Unlike content based filtering, which suggest only similar products or domain specific products, collaborative filtering recommendation systems allows users to find similar products and jump (or switch) to other categories of products based on similarities with other users and products.  In this case, we explored 3 different ways to use collaborative based filtering.\n",
    "\n",
    "1. The first method suggests products that other users like to a specific user based on their rating of a specific product.  Essentially, it finds users that rated a product similar to the specific user and returns the top products the other users liked.  This method was used as an introduction to recommendation systems with a simple, built from scratch, recommender that did not incorporate actual training of models or prediction methods.\n",
    "\n",
    "\n",
    "2. The second method predicts what products a user may like based on past rating history and the rating history of other users.  This method is not specific to the rating of one product like the first method.  It is a ratings based method that predicts the expected ratings a user would give a product and ranks the highest expected rated products for that user.  Unfortunately this method had to use a sample of the full dataset to train.\n",
    "\n",
    "\n",
    "3. The third method predicts products similar to a specific product by finding the nearest neighbors to that product.  This method is good for users who may want to purchase products as bundles.  It is not ratings or user based as the previous two methods are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
